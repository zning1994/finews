---
layout: post
title: "资深架构师眼中的“虚拟人”：多模态人机交互、AI学习及算力"
date: 2022-01-17 14:03:37 +0800
categories: zhongguodianzibao
tags: 中国电子报新闻
---
<p>“你好，小布！附近有什么好吃的？”用户的话音刚落，手机上就出现了一个小窗口，让附近饭店的排名一目了然。对话中的“小布”是OPPO手机自带的智能助手，并在前段时间成为业界首个基于“虚拟人”多模态交互的手机智能助手。去年年末，“虚拟人”市场快速升温。除OPPO之外，京东、百度、阿里巴巴等科技企业都推出了自己的超写实数字人，B站还专门为虚拟主播开设分区，“虚拟人”已经走进了人们的生活。</p>
 <p>“虚拟人”受到热捧的重要原因之一，是人们对人机交互的更深层次需要。从单纯的文本到语音，再到计算机视觉等技术的融合，人的天性倾向于融合视觉、听觉等多种感官的交互过程。而“虚拟人”背后的多模态人机交互技术，恰好能够满足人对外界信息获取逐渐升维的过程，让“虚拟人”看起来像人、听起来像人，更加具备人的温度。</p>
 <p>“虚拟人”背后的技术支撑</p>
 <p>人机交互走过了键盘交互、触摸交互、语音交互等若干阶段。如今，由于用户对人机交互的便利性、自然性以及准确性提出了更高要求，更加智能化且能够理解用户意图的多模态人机交互，开始成为人机交互发展的重要趋势。</p>
 <p>在接受采访时，OPPO小布助手首席架构师万玉龙向《中国电子报》记者表示，当深度学习算法在各技术方向逐渐趋于产业化，智能交互变得愈发重要。在这之后，传感器、视觉技术、语音技术和自然语言处理技术等都进行了迭代升级，多种技术的融合形成了多模态人机交互方式。</p>
 <p>通过文字、语音、视觉的理解和生成，结合动作识别和驱动、环境感知等多种方式，多模态人机交互能够充分模拟人与人之间的交互方式。万玉龙给记者举例道，地铁、银行、商场等复杂环境下的服务类机器人就是结合传感器、人脸识别、语音交互等技术来帮助人们完成信息查询、购票、商家导航等需求任务。</p>
 <p>现阶段，多模态人机交互领域最火的代表就是“虚拟人”了。万玉龙向记者表示，得益于元宇宙概念的大火，“虚拟人”这一元宇宙世界的“小切口”也得到了业界的广泛关注。</p>
 <p>2021年第三季度，OPPO推出智能助手小布的首个“虚拟人”版本，为“虚拟人”市场再添一把火。相关资料显示，小布“虚拟人”涵盖了视觉、语音、自然语言处理等多模态融合算法，采用多种基础创新技术，可以实现与用户在多个场景生态下的内容服务、实时交互以及情感化交互。</p>
 <p>作为多模态人机交互领域的重要成果之一，“虚拟人”背靠前端声学处理、语音唤醒、语音识别、对话理解和管理、语音合成、计算机视觉和图形学等技术支撑。万玉龙对记者谈道，语音交互是在对话理解的基础上，通过对话管理生成对应的回复话术和内容服务，结合语音合成技术(TTS)生成播报音频；虚拟人多模态交互则需要在此基础上，进一步理解播报文本所蕴含的表达信息，通过文本和语音分析，生成对应表情、嘴形和动作。</p><p>“除了嘴形以外，要想呈现出眼部、脸部的表情，以及我们说话或者非常开心时做出的动作，都需要3D人物设计和建模，并实时的根据表达内容预测人物身体各部位的驱动参数，进而结合渲染引擎实现对人物模型的驱动。”万玉龙举例道，比如某个人在说“大”的时候，他的嘴型就会张得很大，然后说字母“O”的时候嘴型会呈现出一个圆形。</p>
 <p>为了让智能助手变的更加智能，人机互动过程还会涉及知识图谱、内容推荐等宽泛的技术领域。</p>
 <p>AI学习还需要大量数据积累</p>
 <p>现阶段，虚拟人在三个环节上存在关键性的技术难点。万玉龙向《中国电子报》记者指出，第一，从形象生成来说，用户会越来越希望他们所构建出来的“虚拟人”，在形象上显得更加逼真，比如发丝、衣服的纹理等很细致入微的特点都能完美呈现。只有“虚拟人”真正像一个活生生的人站在用户面前，用户才能感觉到自己与虚拟人之间的距离被拉近。</p>
 <p>“但要实现这一点，涉及的技术点其实非常多，处理起来会非常困难，且制作成本居高不下。”万玉龙对记者坦言。</p>
 <p>第二，在形象驱动方面，“虚拟人”的行动需要呈现得更加流畅和自然，而不是像机器人那样僵硬。人在交流表达的时候，不管是手、眼还是表情，所有的肢体动作都是根据表达的内容和情绪去变化的。但“虚拟人”想要达到这点，还需要更强大的AI机器学习和深度学习。AI只有在学习了大量真人表情、肢体表达的数据之后，才会慢慢趋近于真人，但这是一个非常漫长的过程。</p>
 <p>第三，形象互动对于虚拟人来说尤为重要，因为“虚拟人”最大的卖点就在于互动性。如果“虚拟人”不能为用户提供自然、舒适的交互体验，用户很快就会失去兴趣。但这种互动性的提升其实并不简单。比如，人在回答问题时，通常会结合语句“上下文”，运用自己的背景知识很快给出合适的答复。智能虚拟人助手则需要通过学习大量人跟人的对话数据，来构建和丰富知识库。这些数据的获取并非易事，因为AI学习所需的数据量十分庞大，且需要不断更新，其中的难度不言而喻。而且，在获得数据之后，AI还需要对获取的数据进行质量把控和筛选，很难做到逐一排查。AI如果没有辨别能力，在学习完数据之后很难对习得内容进行修改，所以有些不合时宜的语句很可能会对用户造成不良影响。</p>
 <p>另外，假设人们问AI一个知识点，它也许会从知乎或者其他网站上选一个答案进行反馈，但这就涉及知识产权的问题，同时AI所学习到的知识也无法保证具有绝对专业性。比如，人们在生病的时候不能去询问智能虚拟人助手自己该吃什么药，因为无法保证所获取到的答案的专业性。如果“虚拟人”助手给出一个错误的答案，人的健康可能会出现问题。所以，“虚拟人”要想与用户进行无障碍且自然流畅的交流，还需要更多的技术积累与沉淀。</p>
 <p>向具备更多应用价值的领域拓展</p>
 <p>尽管“虚拟人”在技术上尚存难点，但近年来的底层技术其实也在不断进步。万玉龙对《中国电子报》记者表示，不管是语音识别、对话理解、语音合成等语音交互技术，还是唇形驱动、表情驱动等多模态驱动参数预测技术，建模流程和方案都在变得更加简单。</p>
 <p>“从机器学习的模型层面来说，算法的迭代已经让模型训练和调优进入到了‘门槛越来越低’的阶段。”万玉龙表示。</p>
 <p>算力的提升也会让“虚拟人”形象更加接近真人。万玉龙对记者说，手机等设备端的算力正变得越来越强，云端服务器的算力也在不断增强，促使AI工程师们可以生成更加复杂、更加真实的人物形象。</p>
 <p>2021年，英伟达CEO黄仁勋的一段“虚拟人”演讲视频风靡全球，英伟达推出的Omniverse平台进一步走入大众视野。据了解，Omniverse平台是英伟达推出的实时3D设计协作和虚拟世界模拟平台，旨在通过将图形、AI、模拟和可扩展计算整合到一个平台上，成为连接虚拟世界的基础。</p>
 <p>万玉龙表示，借助自身强大的GPU算力，英伟达构建了一个看上去比较真实的人物形象。这进一步表明，目前的算力确实提升了一个台阶，算力的提高也让超写实人物的渲染变得更具可行性。一方面是对话式AI技术的不断升级，另一方面就是虚拟人物的形象构建能力越来越强，整个对话体验也变得更加智能，对话理解、知识图谱等认知能力的建设更上一层楼，助力“虚拟人”产品化的能力日益提升。</p>
 <p>有人说，汽车是下一代“移动终端”，有望成为实现人机互动、情感交互的移动载体。那么，“虚拟人”是否有可能出现在智能座舱领域？</p>
 <p>在万玉龙看来，不管是手机还是汽车，其实都可以被视为一个智能交互载体。OPPO推出的小布“虚拟人”目前的着力点主要还是在提升手机、电视、可穿戴设备等智能设备的交互体验。万玉龙表示，如果智能座舱等设备形成一定的规模之后，智能助手在这些设备中一定会有与用户频繁交互的机会，所以必然会产生一些场景应用价值。只要是有应用价值的领域，“虚拟人”的触角其实都是可望又可及的。</p><p class="em_media">（文章来源：中国电子报）</p>

<http://finews.zning.xyz/html_News/NewsShare.html?infoCode=NW202201172250287667>

[返回中国电子报新闻](//finews.withounder.com/category/zhongguodianzibao.html)｜[返回首页](//finews.withounder.com/)