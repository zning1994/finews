---
layout: post
title: "刘军：元宇宙是数实融合的数字载体 需要强大算力基础设施"
date: 2022-04-08 11:24:57 +0800
categories: guangmingwang
tags: 光明网新闻
---
<p>近日，浪潮信息副总裁、AI&HPC产品线总经理刘军受邀出席新智元“元宇宙新人类”论坛，在《元宇宙服务器MetaEngine》主题报告中，分享了浪潮信息对元宇宙的认知，元宇宙面临的技术挑战，以及如何打造元宇宙新型基础设施的见解。</p>
 <p>【以下内容基于演讲实录整理】</p>
 <p><strong>元宇宙是数实融合的数字载体</strong></p>
 <p>数实融合当前已经成为一种潮流的趋势，当数字技术日益融入经济社会发展各领域、全过程，持续推动着物理世界数字化、数字世界智慧化，逐渐形成了一场涵盖个人生活方式、社会生产方式和国家治理方式的全面变革。</p>
 <p>数实相融就是数字化世界同物理世界的融合，用数字世界来引导现实世界的运行，用数字世界的智慧化实现现实世界的智慧化。</p>
 <p>元宇宙本质上是更高度的数实融合，它是数实融合的数字载体，这里我们以数字孪生和虚拟人为例来谈谈。</p>
 <p>数字孪生是元宇宙的数字空间基础，它可以将物理对象以数字化的方式在虚拟空间进行动态呈现，它的应用体现在多个方面，比如孪生工厂，可以动态的呈现从生产制作的全过程动态管理，实现运转效率的大幅提升；孪生城市可以在数字世界推演天气环境、人口土地、产业交通等要素的交互运行，绘制城市画像，帮助城市规划、城市治理的效率提升；孪生基建可以让我们在修建高速公路、楼体建筑时，在数字世界对工程进行仿真模拟，评估结构和承力，在工程交付后的维护阶段评估工程是否可以承担特殊情况的压力，以及监测可能出现的事故隐患。</p>
 <p>数字虚拟人是元宇宙的重要实体(Entity)和生态，就像是元宇宙世界中的公民，是人类身份在虚拟世界的载体。利用数字虚拟人，人们也可以提升很多工作效率，比如虚拟主播可以7*24小时的进行新闻播报，可以让人们全天候的了解天下大事，虚拟医生可以通过打通就诊数据、跟踪上万种细微指标特征差异，打破时间和空间，实现医生就诊病人从1对1转变为1对多管理，虚拟模特在疫情下缓解了模特紧缺的市场情况，解决模特的供不应求。</p>
 <p><strong>元宇宙：认知世界再现世界</strong></p>
 <p>元宇宙，可以说是一个认知世界、再现世界的过程，这个过程涉及到在线协同建模、高精度仿真、实时渲染、智能交互等多个环节，每个环节下都有对应的关键技术、软件栈和算法工具。</p>
 <p>首先，构建元宇宙需要进行3D建模，最近比较前沿的还有AIGC(利用GAN/多模态模型生成内容创作)，这部分的工作需要多人在线协同构建。</p>
 <p>由多人在线协同生成3D模型生成后，需要在元宇宙中仿真运行，通过结构仿真、感知仿真和控制仿真可以对模型进行验证，如果说建模是对物理实体理解的模型化，那么仿真就是验证和确认这种理解的正确性和有效性的工具。</p>
 <p>通过光线追踪、光栅化、数据流传输可以让虚拟人、数字世界更加逼真，为用户带来超现实的感官体验，呈现出一个更加丰富多彩的数字世界，拥有逼近现实世界一样的沉浸感。</p>
 <p>利用CV/NLP/ASR/TTS等AI技术，让数字世界的虚拟人可以能听、会说、能交互，从而打破数字世界和物理世界的边界，实现线上线下的交融。</p>
 <p>元宇宙通过以上多个环节、多个工具才能达到超越感官、智能交互的水平，像现实世界一样丰富多彩。</p>
 <p><strong>元宇宙需要强大的算力基础设施</strong></p>
 <p>元宇宙的出现和发展带来的不仅有精彩，还有挑战，元宇宙构建的各个环节都需要用到不同类型的算力支撑，也就是元宇宙的算力基础设施。</p>
 <p>大规模、高复杂的数字孪生空间、数字人和其他实体角色的建模需要众多设计师协同创作完成，现实世界和数字世界的交互则需要实时、高清的3D渲染算力和低延迟的网络数据传输，增加了云端协同的处理需求。</p>
 <p>元宇宙的应用会涉及到动力、热力、流体等多类物理仿真，这需要用到高精度的数值计算，来支撑物理仿真和科学可视化。</p>
 <p>让数字世界无限接近现实世界，需要高逼真、沉浸感的3D场景构建和渲染。举个iMax 3D电影的例子，比如《战斗天使阿丽塔》这部电影，其中阿丽塔高度拟真的视觉特效令人震撼，这样以假乱真的渲染效果来源于巨大的算力消耗：主角13万根发丝每根都需要进行单独渲染，仅1帧画面渲染就要耗费100个小时，而元宇宙的渲染不仅只涉及一个虚拟人，还包括建筑、城市等其他元素，这需要巨量的图形图像计算支撑。</p>
 <p>同时，元宇宙还会涉及到人机交互等AI应用场景，由AI驱动的数字人往往需要结合语音识别、NLP、DLRM等AI算法从而实现交互能力，这些模型的背后需要强大的AI算力来支撑其训练和推理需求。</p>
 <p>可以看到，要构建高度拟真的数字世界并实现数亿用户实时交互的“元宇宙”，当前面临着场景规模大、场景复杂度高，以及多设计师和多部门协作、极高逼真数字元素制作，实时渲染、仿真和交互等诸多挑战，并对支撑元宇宙构建和运转的核心源动力——算力提出更高的要求。这种要求不仅仅是高性能、低延迟、易扩展的硬件平台，还有端到端、生态丰富、高易用的软件栈。</p>
 <p><strong>浪潮元宇宙服务器MetaEngine</strong></p>
 <p>浪潮元宇宙服务器MetaEngine正是为满足这些苛刻要求而设计的软硬一体化基础设施。</p>
 <p>作为元宇宙生态的底层算力支撑平台，MetaEngine将承载元宇宙构建和运行所需的技术和工具，提供对AI、渲染、仿真、建模等负载的算力支持，满足元宇宙创建所需的“协同创建、实时渲染、高精仿真、智能交互”4大作业环节的不同类型算力需求，并通过高速、无阻塞的网络信道，按需扩展至大规模算力集群。浪潮元宇宙服务器结合业界最强软硬件生态，协同优化加速数字孪生世界构建，为用户打造高效的元宇宙协同开发体验。单台元宇宙服务器即可支持256位元宇宙架构师协同创作，每秒AIGC 2000个数字场景，1000位VR/AR用户共享10K超高清3D数字世界顺畅体验。</p>
 <p><strong>元宇宙服务器产品方案架构</strong></p>
 <p>在硬件上，MetaEngine采用浪潮领先的异构加速服务器的旗舰系统，支持最先进的CPU和GPU，具有强大的RDMA通信和数据存储能力，支持强大的渲染和AI计算能力。</p>
 <p>在软件上，可以支持对应每个作业环节的各类专业软件工具，用户可以根据使用习惯灵活选择，同时系统集成了NVIDIA Omniverse Enterprise，为用户准备了丰富的开发套件，包括专门用于结构、感知、控制仿真的Simulation SDKs，用于渲染、实时光追、AI降噪的SDKs，用户可以通过Kit功能将这些不同的SDK进行模块化的组合，快速完成定制化App或者微服务的开发，当然这里已经为用户准备好了一些广泛适用的App比如用于建模和渲染的Create，用于可视化的View，更为重要的是，用户通过App开发的内容可以通过数据库和协作引擎NUCLEUS，建模工具互联插件CONNECT与第三方专业软件工具无缝连接，目前CONNECT已经提供了20多种Plugins，支持与3DS MAX、UE、MAYA等软件互联。</p>
 <p>MetaEngine的目标是构建一个端到端、生态丰富和高易用的协作平台，为用户打造一站式元宇宙开发体验。</p>
 <p><strong>MetaEngine全面支持Omniverse</strong></p>
 <p>当前，MetaEngine已经全面支持英伟达的Omniverse Enterprise，将高性能 GPU 的图形计算、AI计算与高速存储访问、低延迟网络和精确计时相结合，是一个数据中心级的软硬一体解决方案，专用于为大规模数字孪生提供算力和应用支持，以实时创建和运行非常复杂的模型和逼真的仿真环境。</p>
 <p>目前的MetaEngine元宇宙服务器集成A40的专业GPU，CX6 Dx高速网卡，并与企业级管理和编排软件相结合，为用户准备了丰富的建模、渲染、仿真套件。同时，可以将32台MetaEngine组合成为1个集群式的可扩展单元，多个可扩展单元可以继续横向扩展组成更大规模集群，可提供非凡的计算性能和超高的网络带宽，满足工厂、城市乃至更大规模复杂仿真和实时数字孪生的需求。</p>
 <p>在这里，我也将为大家分享如何用浪潮MetaEnigne创建数字孪生和虚拟人。</p>
 <p><strong>MetaEngine创建数字孪生</strong></p>
 <p>首先，以新品设计、流水线调度生产、上市为例，谈一谈MetaEngine如何创建运行数字孪生，来优化工作流，提高生产效率。当生产及需求达到一定规模时，生产、配送、分拣的过程就成为了一个系统工程性问题，如饮料、汽车等各行业的大规模制造公司。使用数字孪生让虚拟世界的高精仿真代替现实世界的运行，在产品设计生产、调配之前，模拟其过程取得物理装置最优的参数配置，提高效率赢得市场。</p>
 <p>如何建造一个流水线上的数字孪生？MetaEngine提供元宇宙构建所需的多元算力和Omniverse组件，为构建和运行该数字孪生提供基础能力。</p>
 <p>首先是在线建模，按照1:1数字模型创建工厂的建筑、流水线等生产交付全过程。Connect组件提供20多个第三方建模软件的连接插件，允许用户使用第三方建模工具接入协同建模，Omniverse使用统一数据格式USD与第三方建模软件(SketchUp/Revit)进行数据交互，Nucleus数据库提供多人数据管理功能，允许多用户同时修改可视化、渲染3D-USD文件。</p>
 <p>高精仿真阶段使用Simulation组件仿真新产品的材质及物理属性，根据高逼真的虚拟物品，使用Replicator完成仿真环境的部署、搭建。Omniverse丰富的材质库可以为设计模拟物品，提供更好的逼真度，配合使用物理仿真、动画制作的软件(Ansys/Houdini)可以完成整个流水线和物品的高精仿真；Replicator组件则根据仿真结果生成AI模型训练需要的合成数据环境。</p>
 <p>实时渲染阶段，使用Renderer组件对仿真环境中的材质、光照条件实时渲染画面，生成用于训练AI模型的合成数据。根据合成数据在MetaEngine中训练我们的AI视觉模型，提供物理实体及流水线流程的监控及理解。</p>
 <p>智能交互阶段，将在MetaEngine中训练完成的AI模型部署于物理环境与虚拟环境，虚拟环境中的AI推理指导物理实体行为，物理环境中实际反应再返回虚拟环境指导模型融合训练。虚拟世界中如检测到画面中的拥堵或者空闲，可以反馈到物理流水线改变作业状态，反之物理流水线上真实的结果可以生成真实数据继续更新AI模型。</p>
 <p><strong>MetaEngine创建虚拟数字人</strong></p>
 <p>我们再以高逼真的交互型虚拟数字人的制作及使用为例，依然按照“协作建模---高精仿真---实时渲染---智能交互”的作业流程来看如何用MetaEngine创建虚拟人。</p>
 <p>首先可以使用UE Metahuman/CHARACTER CREATOR配合Omniverse Nucleus/Connect进行3D人物形象及人脸建模。然后通过高精仿真，让虚拟数字人更加自然、真切的与我们交流，比如对毛发的模拟，12万根毛发如何在风中飞舞，这得需要强大的算力支撑，还需要借助AI模型生成逼真的手势和面部表情。</p>
 <p>再就是实时渲染，MetaEngine中的Omniverse RTX Renderer可以提供实时渲染能力，让人物动画及其场景实时立体地展示在我们面前，通过屏幕或XR设备进行沟通交流。</p>
 <p>最后是智能交互使用，这块需要有大量的AI模型提供支撑，把整个智能交互的流程放大来看。用户首先通过语音和视频分别通过ASR 和 Vision AI模型进行推理，得到文本及视频动作理解；将文本、动作理解融合送入的NLP语言模型如源1.0生成语言文本，再将语言文本转化为语音或动作语言表述，通过TTS模型将文本转化为语音，语音驱动Avatar制作的虚拟数字人，产生面部行为(audio2face应用)动作手势(audio2gesture)，并通过RTX Renderer实时渲染能力生成动画视频作为输出与用户交互。</p>
 <p>当然，元宇宙不仅只有数字孪生和虚拟人。元宇宙要实时地映射现实世界，在元宇宙中再现工业、农业、服务业、社会、经济、文化、城市、乡村、地球等现实世界，用户“身临其境”地在其中社交、娱乐、会议、协作、旅游、购物、教育，所有人都可以在其中互动，要达到这样的目标，还有很长的路要去走，需要不断探索和发现更有效率的实现元宇宙的创新技术和方案。</p>
 <p>如同发展汽车产业需要高速公路一样，汽车是应用，公路是基础设施，元宇宙也需要基础设施。MetaEngine元宇宙服务器即是浪潮为加速元宇宙产业提出的算力基础设施。(战钊)</p><p class="em_media">（文章来源：光明网）</p>

<http://finews.zning.xyz/html_News/NewsShare.html?infoCode=NW202204082336407532>

[返回光明网新闻](//finews.withounder.com/category/guangmingwang.html)｜[返回首页](//finews.withounder.com/)