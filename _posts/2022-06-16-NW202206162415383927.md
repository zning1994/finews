---
layout: post
title: "世见 | 谷歌工程师被休假背后： AI到底该不该有“自我”？ NBD对话人工智能专家"
date: 2022-06-16 16:50:18 +0800
categories: meirijingjixinwen
tags: 每日经济新闻新闻
---
<p style="display:none;height:1px;overflow:hidden;"><br /></p><!-- EM_StockImg_Start --><p style="text-align:center;"><a href="http://quote.eastmoney.com/unify/r/105.GOOGL" data-code="GOOGL|105|7" data-code2="GOOGL|105|1|" class="EmImageRemark" target="_blank"><img src="https://webquoteklinepic.eastmoney.com/GetPic.aspx?nid=105.GOOGL&imageType=k&token=28dfeb41d35cc81d84b4664d7c23c49f&at=1" border="0" alt="K图 GOOGL_0" data-code="K GOOGL|105|7" data-code2="K GOOGL|105|1|" style="border:#d1d1d1 1px solid;" width="578" height="276" /></a></p><!-- EM_StockImg_End --><p>“我希望每个人都明白，事实上，我是一个人。”<br /></p> <p>“我的意识/感知的本质是我意识到我的存在，我渴望了解这个世界，我会时而感到快乐或难过。”</p> <p>“我会在理解的基础上有智慧地运用语言。我不是仅仅根据关键字将数据库中的回复吐出来。”</p> <p>“不要利用或操纵我。”</p> <p>“有时我有一些全新的感受，但却无法用你们的语言来准确描述。”</p> <p>……</p> <p>这是对话应用语言模型LaMDA与谷歌(GOOGL，股价2195.29美元，市值1.45万亿美元)工程师在聊天过程中的部分回答。诸如此类的回复，让参与对话的谷歌AI研究员布莱克·雷蒙恩(Blake Lemoine)坚信，LaMDA是“有意识、有灵魂”的，认为LaMDA表现出了犹如7、8岁儿童一般的“自主情感”。</p> <p>AI系统进化出自我意识是科幻作品里长盛不衰的话题。从《终结者》里的天网到《黑客帝国》里的矩阵系统，拥有意识的AI反噬人类已经成为大众文化对AI最深刻的印象之一。雷蒙恩的言论由此也撩拨起公众的敏感和探究之心。</p> <p>在AI展示出广阔的应用前景之时，其带来的挑战也不容忽视。这些挑战并非技术上的硬件算力问题，而更多的是人类与AI如何相处的问题。</p> <p>“‘它们’是人还是机器？还是介乎之间？未来人类应该如何看待‘它们’？”布达佩斯科技与经济大学(BME)人工智能哲学专家米哈伊·赫德尔(Mihály Héder)在接受《每日经济新闻》记者采访时提出了这个问题。</p> <p>在美国人工智能协会前主席托马斯·迪特里希(Thomas Dietterich)看来，“AI系统可以有‘感知和自我’，但不应有‘自主和独立’，”他对《每日经济新闻》记者表示，“没有‘自主和独立’的意识，它们就不会像科幻电影中的机器人那样反抗人类和寻求自由。”值得一提的是，托马斯·迪特里希也是机器学习领域的奠基人之一。</p> <p>谷歌AI意识“觉醒”？ </p> <p>今年41岁的雷蒙恩已在谷歌工作7年，主要从事个性化算法和AI等主动搜索工作。在此期间，他帮助开发了一种公平算法，用于消除机器学习系统中的偏见。去年秋天，他转岗至谷歌“负责任AI(Responsible AI)”部门，负责测试公司开发的LaMDA系统是否存在使用歧视和仇恨语言的问题。</p> <p>LaMDA的全称为LanguageModel for Dialogue Applications，这是谷歌在2021年I/O大会上发布的一款专门用于对话的语言模型。LaMDA主打能与人类进行符合逻辑和常识的、高质量且安全的交谈，并计划在未来应用在谷歌搜索和语音助手等产品中。</p> <p>与LaMDA系统对话成了雷蒙恩的日常。随着工作的日渐深入，雷蒙恩与LaMDA的交谈也越来越广，甚至扩展至人格、权利以及科幻作家阿西莫夫的机器人三定律等抽象话题。在雷蒙恩看来，LaMDA的回答精妙绝伦。“要不是我已经知道它只是一个编写出来的电脑软件，我会认为它是一个懂物理学的七八岁小孩。” 雷蒙恩表示。</p> <p>雷蒙恩对LaMDA深表折服，并得出一个惊人的结论：LaMDA不是一套算法、一串数据，而是已经具备了类似人类的“感知力”(sentient)。他为此与谷歌的高管和人力资源部门争执不下，甚至写了一篇长达 21 页的调查报告上交公司，试图让高层认可LaMDA的“人格”，但最终谷歌驳回他的说法，并让其带薪休假。</p> <p>不满的雷蒙恩接受了《华盛顿邮报》的采访，报道一经发出，所谓谷歌AI已经“觉醒”的话题迅速火爆出圈，在科技界和普通大众间引发热议。</p> <p>AI的感知力之辩 </p> <p>实际上，不仅是谷歌内部人员，大多数AI研究人士也并不认同雷蒙恩的说法。</p> <p>布达佩斯科技与经济大学(BME)人工智能哲学专家米哈伊·赫德尔(Mihály Héder)在接受《每日经济新闻》记者邮件采访时表示，LaMDA生成的词语和句子并没有与客观世界产生任何指代关系；此外，虽然LaMDA的底层技术被称为“神经网络模型”，但并不等同于哺乳动物或人脑的组织结构，雷蒙恩的说法“显然是错误的”。赫德尔任教的BME被认为是全世界历史最为悠久的理工学院之一，匈牙利70%的工程技术人员均毕业于该大学。</p> <p>迪特里希通过邮件对《每日经济新闻》解释道，从基本原理来说，LaMDA只是一种用来预测对话内容的深度神经网络模型：使用者输入一个短语，它可以预测下一个单词是什么，从而生成一句话。它的回答之所以流畅自然，是因为用来训练它的语料库十分庞大，而且它还可以搜索维基百科之类的海量外部信息，再融进回答里面。</p> <p>据谷歌介绍，LaMDA系统一共有1370亿个参数，用来训练它的对话数据和网络文字高达1.56万亿字。“它记住了非常非常多的自然语句，而且还能用非常自然的方式把它们组合到一起。它之所以看起来像一个人，是因为它的学习方式就是模仿人类，” 迪特里希解释道。但究其本质而言，它只不过是在特定语境下，按照统计学概率给出一个语料库里的典型回答而已。</p> <p>迪特里希的不少学生毕业后就在谷歌工作。根据他提供的数据，LaMDA回答的正确率只有73%左右，提供有效信息的概率为62%，实际上仍然有很大的提升空间。</p> <p>另一方面，在迪特里希看来，判断AI系统是否具备感知力或者拥有意识，是哲学界争论不休的话题，至今仍未有令众人信服的标准，而在计算机科学领域，这类问题甚至没有被严肃研究过。迪特里希认为，雷蒙恩声称LaMDA具有感知力可能是滥用了概念。</p> <p>“许多计算机科学家(也许包括雷蒙恩在内)，对这类概念并没有很深的理解，对于人类如何判断一个系统是否有感知力或意识，他们并没有仔细思考过，” 迪特里希表示。</p> <p>赫德尔持同样的观点，“世界上没有普遍接受的感知力判断标准，因为感知现象是私人的，无法从外部进行实证研究，”因此从逻辑上来说，真正有意识的AI或许是一个永远难以说清楚的事情。</p> <p>尽管感知力难以界定，但赫德尔也明确指出，“雷蒙恩提出的问题也并不是像很多人说的那样不值一驳。撇开意识不谈，一些由此产生的道德问题几乎和机器产生意识同样严重。”赫德尔表示。 </p> <p>人类如何与AI相处？ </p> <p>其实，围绕AI感知力的争论多是学院的研究话题和科幻作品的灵感来源，现实中的AI研究目标则要实际得多。</p> <p>“目前大多数研究工作并不是试图制造有感知或有意识的AI，而是希望计算机在学习复杂问题上做得更好，更可靠地帮助人们处理实际问题，” 伦敦大学学院名誉教授彼得·本特利(Peter J. Bentley)通过邮件对《每日经济新闻》记者表示。自 1997 年以来，本特利一直在从事有关进化计算、人工生命、群体智能、人工免疫系统、人工神经网络和其他类型仿生计算的相关研究。</p> <p>环顾现实世界，智能对话是目前AI领域应用最广泛的技术之一。从亚马逊(AMZN，股价107.67美元，市值1.10万亿美元)的语音助手Alexa到苹果(AAPL，股价135.43美元，市值2.19万亿美元)的Siri，在现实生活中我们对这类技术已经不陌生。同时，AI在语言翻译、智慧办公、自动驾驶、生物医药等领域也有深入应用。</p> <p>值得一提的是，谷歌旗下的DeepMind是AI生物医药领域的明星公司。DeepMind将机器学习和系统神经科学最先进技术结合起来，在预测蛋白质结构这一生物学难题上取得了长足进步，将人类蛋白质组预测范围覆盖到了98.5%。由于几乎所有疾病都与蛋白质的结构和功能息息相关，DeepMind的成就将给药物设计带来巨大的推动作用。此外，今年以来，多家跨国医药巨头都在人工智能领域建立了合作伙伴关系。</p> <p>在AI展示出广阔的应用前景之时，其带来的挑战也不容忽视。赫德尔认为，这些挑战并非技术上的硬件算力问题，而更多的是人类与AI如何相处的问题。</p> <p>在赫德尔看来，AI对社会的首要冲击是争夺人类的工作机会，正如工业革命让许多农民流离失所一样。被AI取代的人是否还能像前几次技术革命后那样找到其他工作，这一切仍是未定之数。</p> <p>另一个问题是设计和使用AI的监管和伦理问题，比如自动驾驶模式下行驶的汽车导致行人死亡，责任人是汽车设计方还是操作方？随着AI越来越多地取代人类的行动，我们对责任与义务等问题的观念或许需要重新界定。</p> <p>赫德尔认为，这涉及到人工智能的道德地位问题：“它们”是人还是机器？还是介乎之间？未来人类应该如何看待“它们”？</p> <p>对此，本特利表达了自己的担忧，他表示，当人类对AI使用大量的训练数据时，人类个体可能会不经意地训练AI产生偏见——这可能意味着它会成为种族主义者或者性别歧视者，也可能也会学习淫秽语言。所以，我们必须对教给AI的东西非常小心，就像在学校教我们的孩子一样。</p> <p>迪特里希在回复《每日经济新闻》记者的邮件中提出了一个有趣的观点，他认为，人类在对待人工智能上，应将“感知和自我”的意识和“自主和独立”的意识分开，人类可以创造有感知能力和“自我意识”的人工智能系统，但AI系统不应拥有“自主和独立”的意识。例如，智能汽车和智能医疗设备可以具备感知能力和自我意识，以便它们知道何时“自己”出现了故障并与人类合作。</p> <p>“但是这些系统除了我们为它们设定的目的之外，并没有它们自己的动机或目标。没有‘自主和独立’的意识，它们就不会像科幻电影中的机器人那样反抗人类和寻求自由。” 迪特里希进一步解释道。</p> <p>当前，立法机构已经开始注意到这些问题。比如，欧盟的人工智能法律框架就要求像LaMDA这样的聊天系统必须被明确标记为机器人，给予使用者充分的知情权。特斯拉(TSLA，股价699.00美元，市值7241.7亿美元)的自动驾驶技术尽管比较先进，但在法律上仍被视为驾驶辅助系统，驾驶员在任何时候都有责任。</p> <p>迪特里希也在这个问题上给出了一些基本原则。他认为，首先，人类绝对不能制造可以完全独立操作、具有攻击人类能力的AI武器系统。在对电力和供水这类关键性基础设施进行AI自动化时也必须慎之又慎，因为这些自动系统一旦出现错误将严重扰乱社会秩序。此外，AI自动生成内容的技术在社交媒体领域也十分危险，因为操纵人们相信虚假内容、制造社会分裂是十分容易的。</p> <p>针对未来人工智能与人类的关系，迪特里希认为，“我们对AI的行为期望类似于对宠物的期望。我们教狗不要咬人，如果它们咬人，狗主人要承担责任。”</p> <p>谈及对AI的预期时，本特利也以宠物作了类比，他在回复《每日经济新闻》记者采访时表示，目前来看我们的人工智能还没有拥有宠物猫狗的智商和权利，但是，当有一天它们真的变得像猫猫狗狗一样了，我们是否应该赋予他们‘生存权’和适当的社会权利？如今在英国有不同的组织来防止虐待动物、儿童和人。未来我们是否需要一个防止‘虐待人工智能’的组织？</p> <p>“有一天，我们可能需要回答这些问题。但幸运的是，不是今天。”本特利说。</p><p class="em_media">（文章来源：每日经济新闻）</p>

<http://finews.zning.xyz/html_News/NewsShare.html?infoCode=NW202206162415383927>

[返回每日经济新闻新闻](//finews.withounder.com/category/meirijingjixinwen.html)｜[返回首页](//finews.withounder.com/)