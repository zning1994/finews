---
layout: post
title: "颠覆！3分钟 做个“人”吧！"
date: 2022-03-01 16:34:04 +0800
categories: shanghaizhengquanbao
tags: 上海证券报新闻
---
<p>未来，想做一个虚拟人需要多大投入？图像处理器芯片巨头<strong>英伟达</strong>给出的答案是：一段语音，3分钟时间。</p><center><img src="https://dfscdn.dfcfw.com/download/D25520774677237099890_w625h456.jpg" alt="Image" style="border:#d1d1d1 1px solid;padding:3px;margin:5px 0;" width="552" /></center><p>日前，在英伟达举行的一场线上论坛中，一项可能颠覆大众想象的“黑科技”引发热议。当虚拟人制作门槛不断降低时，AIGC(AI生产内容)将成为可能。</p><p>这可能是传媒行业又一次技术的颠覆，也可能构成元宇宙未来的新图景。</p><p><strong>3分钟“造人”</strong></p><p>只需要一段语音，软件就能自动匹配口型生成一位口播数字人。如今这一愿望已然成为现实。此前，英伟达在其元宇宙平台Omniverse上亮相的Audio2face功能，一经推出便引发业内热议。日前，英伟达组织了一场线上论坛，向观众们展示了这项技术。</p><center><img src="https://dfscdn.dfcfw.com/download/D25037175744740181466_w1080h573.jpg" alt="Image" style="border:#d1d1d1 1px solid;padding:3px;margin:5px 0;" width="552" /></center><p>记者注意到，演示中，只需要往操作界面中导入一段音频文件，系统就会自动生成一个拥有丰富面部表情的3D白色模型，这一模型说话的口型与面部肌肉呈现都很自然，整个过程耗时不到3分钟。</p><center><img src="https://dfscdn.dfcfw.com/download/D25084420084458371748_w1080h587.jpg" alt="Image" style="border:#d1d1d1 1px solid;padding:3px;margin:5px 0;" width="552" /></center><p>“这套系统借助了英伟达深度学习的AI技术，”据相关负责人介绍，自然人讲话是一个相当复杂的面部运动，“比如说女生讲话，眉毛挑动的幅度可能更大，因此在适配不同的语音时，模型的面部肌肉都会有所不同。”</p><p>值得注意的是，在软件可视区域生成的模型，本身也被嵌套在英伟达整个超写实数字人的生产链条之中。“在整个Omniverse平台上，不同的组建之间是标准模块化的，因此在Audio2face软件中也可以通用。”据了解，该软件中提供了常用的3D建模功能选项，以便设计师调整设计和渲染。</p><p>“总体来看该软件比较庞大，选项功能和工具非常多，从设计到渲染，覆盖整个流程。”有试用者表示，这并不仅仅像是一个音频驱动人脸动画的软件，更像是一个艺术设计平台，它让我们更多相关的3D建模动画制作工作更容易实现。</p><p><strong>传媒行业将遭新颠覆？</strong></p><p>“英伟达此次Audio2face一个很引人瞩目的点，就在于其全流程和低代码性。”一位业内人士指出，如今低代码和无代码的开发平台日益成为行业发展的主流，这将使得相关领域开发门槛大幅降低。“如果一个虚拟人的制作只需要一个人花上两三天就能完成，那么将为行业带来巨大的商业空间。”</p><p>一个典型的例子便是手语主播。据英伟达相关负责人介绍，目前国内各地手语具有区域性，因此普及国标手语任重道远。“这其实就是虚拟数字人非常好的应用场景，我们现在有技术能做到，只需要输入文本，虚拟人就会自动根据文意，按照标准手语进行演示。”这无疑将大大降低普及成本。</p><p>开发门槛和成本的迅速降低，让数字人有了巨大的应用场景。有业内人士指出，这其中AIGC(AI生产内容)的崛起，或许对媒体行业而言又是一次颠覆性的技术。</p><p>“大众对于内容的消费需求是没有止境的，因此内容损耗比一直都是整个行业需要面对的问题。”一位传媒分析师指出，回顾过去就会发现，历次传媒技术变革的背后，都是内容生产力的一次指数型爆发。</p><p>媒体行业之前是由专业生产者创造内容，此后变成用户产生内容，未来可能是人工智能生产内容。</p><p>“你可以把这类平台看做当年的互联网技术。”该分析师称，互联网让信息传播的门槛降低，从而让媒体由PGC(专业生产者生产内容)逐渐过渡到如今的UGC(用户生产内容)时代，而随着虚拟人等技术的成熟，不受时空制约的AIGC或将成为UGC后的重要内容生产力。</p><p>事实上，近年来各大媒体也纷纷上线了各类虚拟主播。比如新华社率先试水24小时数字主播，接着湖南卫视推出了综艺的虚拟主持人。“我认为第一阶段，是虚拟人将替代传统媒体中那部分重复性工作，比如快讯播报等等，从而大大降低日常运营成本。”一位行业分析师认为，新闻内容消耗速度极快，因此用数字人替代将极大降低成本，同时进一步增加内容供给。</p><p>并且，随着相关技术日渐成熟，数字分身与虚拟现实技术将为个性化定制提供可能。“我们可以畅想一下，以后每个观众也有自己的虚拟形象，那么对于新闻报道他就成为了参与者。”该分析师认为，从读者到观众，再到参与者，数字分身让新闻消费者的身份再次迭代，更加沉浸感的体验，或许会为传媒行业发展带来新思路。</p><p><strong>元宇宙远景已现</strong></p><p>多模态数字人技术的日渐成熟，让元宇宙的愿景逐步有了具体的落地对象。</p><p>所谓多模态数字人，指的是应用了包括语言、表情、动作等多项自然人特征于一身的虚拟人，这其中，更为抽象的“个性”与“性格”则是行业发展的难点。</p><center><img src="https://dfscdn.dfcfw.com/download/D24831380806370235256_w1080h471.jpg" alt="Image" style="border:#d1d1d1 1px solid;padding:3px;margin:5px 0;" width="552" /></center><p>不过如今，科技巨头们已经开始了这一领域的探索。试图真正做到“不仅知人知面，还要知心”。</p><p>据英伟达相关负责人介绍，“每个人讲话的风格是不一样的，包括他的停顿、语调、面部微表情等等，因此大数据无差别采集运算最终就会生成没有个性的‘平均脸’，而我们定向采集某人的一些数据，经过AI深度学习后，就会摸索出这个人的说话风格，实现虚拟人的个性化表达。”</p><p>当数字人开始逐步拥有个性，超现实的临界点或许就会被打破。</p><p>“我认为，随着虚拟人在语言、神态、动作等方面的日臻完善，未来虚拟数字人或许会朝着数字伴侣的方向发展。”一位业内人士认为，这也正是一幅元宇宙的远景。</p><p>不过遥望未来，或许技术还有很长的路要走。“目前来看，我们在算力等方面还有巨大的差距，”英伟达相关负责人表示，和所有数字技术一样，算力是支撑整个虚拟现实技术发展的基石，“我们现在距离那种沉浸式的体验从算力上来看，可能还差着10的六次方倍，而这或许还需要10到15年的时间去发展。”</p><p class="em_media">（文章来源：上海证券报）</p>

<http://finews.zning.xyz/html_News/NewsShare.html?infoCode=NW202203012292954312>

[返回上海证券报新闻](//finews.withounder.com/category/shanghaizhengquanbao.html)｜[返回首页](//finews.withounder.com/)