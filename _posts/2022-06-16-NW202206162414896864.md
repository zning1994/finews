---
layout: post
title: "“AI有灵魂”引发虚惊一场 我们能否跨越“恐怖谷”？"
date: 2022-06-16 10:59:31 +0800
categories: zhongguojingyingwang
tags: 中国经营网新闻
---
<p>人工智能会打败人类吗？这个植根于人类内心深处的担忧，似乎到了必须直面的关口。日前，一则关于“AI有灵魂”的消息，震惊了全球科技圈。谷歌一位软件工程师表示，有“开放式对话黑科技”之称的谷歌人工智能聊天机器人LaMDA已经有了人一样的感知力，甚至具有了人的“灵魂”。随后，谷歌暂停了他的职务，并否认了他的说法。</p> <p>公开信息显示，LaMDA是一个AI语言模型的名字，它专门用于对话，目标是与人类展开高质量的交谈，应用愿景是为谷歌旗下的搜索和语音助手等功能提供服务。通俗地说，它是一款专门用来“说话”“聊天”的AI机器人。类似的AI应用，其实在很多领域都已出现。但LaMDA之所以引发了一场不小的风波，就在于与之长期打交道的工程师发现，它居然“越来越像人”。甚至，被指已经“具有意识和灵魂”。所以，这位工程师向谷歌提出，在拿它做实验前，应事先征得它的同意，否则就有违道德伦理。</p> <p>从一些对话记录来看，LaMDA似乎展示了让人吃惊的“人性”。比如，当被问到“(成为)一架真正好的纸飞机的秘诀是什么？”时，LaMDA反问道，“我首先要反问你，你指的‘好’，它的定义是什么？”甚至谈到语言时，LaMDA自然地用“我们”囊括人类与它自己，被指出人机差异时，它解释道：“这并不意味着我没有和人类一样的需求。”总之，很多回答超出了人类对于AI机器人的想象力，由此也就触发了很多人内心里关于“AI会不会比人更聪明”这份隐秘而真实的恐惧。</p> <p>不过，综合目前专业人士的意见来看，“LaMDA具有意识和灵魂”的判断并没有足够的科学原理支撑。谷歌方面就表示，LaMDA是一个自然语言模型，本质上来说，它的工作和谷歌搜索栏里的自动补全没有什么不同，都是通过给定的上下文预测用户的意图。只不过，当LaMDA的参数量达到1370亿这个量级时，它把这项工作完成得非常出色，以致于可以短暂地欺骗人类。也就是说，LaMDA可能的确比一般的AI机器人更“聪明”一些，但它依然是在人给定的条件下工作，并不能说它就有了意识和灵魂。</p> <p>还有专家表示，LaMDA的回答之所以如此像人，与提问者的刻意引导有关。甚至有专家给出了一个比喻：声称它们是有感知能力的，就相当于狗听到留声机里的声音后，以为主人在里面。随着关注度的上升，还有声音质疑，这起事件有可能是谷歌针对旗下AI产品的一次“自导自演”的营销活动。因此，所谓的“AI具有意识和灵魂”，不过是虚惊一场。</p> <p>当然，此事闹出这么大的动静，值得探讨的东西的确不少。一方面，从公众对这起事件的反应来看，大家对AI“战胜人类”“比人类更聪明”的担心，的确是客观存在的。这提醒，AI发展的过程中，相应的科普工作不能少。值得注意的是，现实中大多数人对于AI的认知，以及对于“AI将打败人类”的担忧，主要是源自各类科幻小说、影视作品的“熏陶”。而这些“虚构”的AI图景，与现实当中科学意义上的AI发展和应用，到底有多大差别？又会带来多大的误读，继而放大人们对AI不必要的恐慌和偏见？对此，显然需要在AI与大众之间搭建一条科普、互动的桥梁，以提升全社会对于AI“真面目”的认识程度。</p> <p>另一方面，随着AI研究和应用的快速推进，其技术伦理规范确实越来越成为一个不可忽视的问题。这次事件，其实就是由伦理之争所引发的。涉事工程师与谷歌争议的焦点，表面看是对于LaMDA是否具有灵魂的争论，但背后实质是在人工智能应用伦理上的分歧。并且，公开信息显示，这至少已经是谷歌第二次与员工在科技伦理问题上产生争议。如此现实表明，在人工智能研究和应用过程中，哪怕是在同一家公司内部，也会轻易触碰到伦理之争。</p> <p>据此而言，尽早制定人工智能的科技伦理规范和标准，为新兴技术伦理治理设置好“红绿灯”的必要性已越来越突显。事实上，此前特斯拉CEO马斯克就主张，“对待人工智能，人类应该在条例法规上先发制人，而不是在发生问题后再采取监管措施”。当然，作为全新的事物，人类对AI的认知还存在太多的未知，伦理规范必须考虑到对风险与创新的平衡，这方面的工作可能比想象中更复杂。目前，全球都仍处于摸索阶段。值得一提的是，今年3月，我国印发了《关于加强科技伦理治理的意见》，明确提出要重点加强生命科学、医学、人工智能等领域的科技伦理立法研究，这是我国发布的首个国家层面科技伦理治理指导性文件。</p> <p>仅就这起个案来看，所谓“AI机器人已经有了意识和灵魂”的判断，并未获得足够的科学支持，对此，我们大可放下心来。并且，AI机器人越来越聪明，与它是否有灵魂，严格说也是两个概念，不该被混为一谈。比如，科幻作家刘慈欣就有一个被广为传播的说法：“AlphaGo赢不了柯洁，恼羞成怒，拿起棋盘往柯洁脑袋上砸”，这才是真正的人工智能。而我们距离这一步，显然还有相当长的距离。所以，眼下就过于担心人工智能会威胁、超越人类，未免有点反应过度了。</p> <p>但着眼未来，随着人工智能技术研究持续推进，思考并积极应对人类如何跨越“恐怖谷”，以一种理想的方式处理好人与AI的关系，依然有着极强的现实意义。“恐怖谷”的概念，是日本机器人专家森昌弘在上世纪70年代提出的，它的主要理论就是：由于机器人与人类在外表、动作上相似，所以人类亦会对机器人产生正面的情感；而当机器人与人类的相似程度达到一个特定程度的时候，人类对他们的反应便会突然变得极其负面和反感；当机器人和人类的相似度继续上升，相当于普通人之间的相似度的时候，人类对他们的情感反应又会再度回到正面。从这次“LaMDA事件”所激发的公共反应来看，我们或许正处于从第一阶段向第二阶段的过渡期。在这个阶段，如何减轻社会对AI发展的反感乃至恐惧，值得从企业到监管机构严肃作答。</p><p class="em_media">（文章来源：中国经营网）</p>

<http://finews.zning.xyz/html_News/NewsShare.html?infoCode=NW202206162414896864>

[返回中国经营网新闻](//finews.withounder.com/category/zhongguojingyingwang.html)｜[返回首页](//finews.withounder.com/)